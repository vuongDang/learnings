# ğŸ“˜ 14-Day Machine Learning Learning Plan
For Rust developers contributing to safetensors or Burn

This plan helps you quickly build the ML fundamentals you need to contribute effectively â€” without diving into heavy math or deep theory.
Focus: tensors, models, formats, inference, file structures.

## ğŸ—“ Overview

Total duration: 14 days

Daily investment: 45â€“60 minutes

Goal: Understand enough ML to confidently contribute to safetensors, Burn, and Rust ML tooling.

## ğŸ§  Week 1 â€” Foundations: Tensors & Transformers

### Day 1 â€” The Illustrated Transformer

ğŸ“ Goal: Understand high-level model architecture & attention.
ğŸ”— Resource:

[https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)

Focus:

what â€œattentionâ€ means

how inputs/outputs flow

high-level model structure

### Day 2 â€” The Illustrated GPT-2

ğŸ“ Goal: Learn about tokenization, embeddings, and weights.
ğŸ”— Resource:

[https://jalammar.github.io/illustrated-gpt2/](https://jalammar.github.io/illustrated-gpt2/)

Focus:

tokens

tensor shapes

model parameters

positional embeddings

### Day 3 â€” safetensors Format Basics

ğŸ“ Goal: Understand how tensor files store model weights.
ğŸ”— Resources:

[https://huggingface.co/docs/safetensors/index](https://huggingface.co/docs/safetensors/index)

safetensors Rust repo: https://github.com/huggingface/safetensors

Focus:

header

metadata

tensor data

safety properties

### Day 4 â€” Burn: Tensors & Devices

ğŸ“ Goal: Understand how Rust represents tensors.
ğŸ”— Resource:

[https://burn.dev/book](https://burn.dev/book)

Read:

Chapter 1: Overview

Chapter 3: Tensors

Chapter 5: Modules

### Day 5 â€” Karpathy: Transformers Explained

ğŸ“ Goal: Understand transformers at a systems level.
ğŸ”— Resource:

[https://www.youtube.com/playlist?list=PLEw8N7FUsmtGhGz5fw5H5mtPQPfdVCAWD](https://www.youtube.com/playlist?list=PLEw8N7FUsmtGhGz5fw5H5mtPQPfdVCAWD)

(watch the Transformer and Attention videos)

### Day 6 â€” Tensor Basics (Shapes, Dtypes, Layout)

ğŸ“ Goal: Know what shapes/dtypes mean in practice.
ğŸ”— Resources:

PyTorch tensor tutorial: [https://pytorch.org/tutorials/beginner/tensors_tutorial.html](https://pytorch.org/tutorials/beginner/tensors_tutorial.html)

Burn tensor docs: [https://burn.dev/book/guide/tensor.html](https://burn.dev/book/guide/tensor.html)

### Day 7 â€” Consolidation / Review Day

ğŸ“ Goal: Solidify understanding.

Suggested activities:

rewatch parts of Day 1â€“2

draw a model block diagram

inspect actual safetensors files (small ones)

ğŸ”¬ Week 2 â€” Systems-Level ML: Weights, Formats, Inference
### Day 8 â€” How ML Frameworks Save/Load Weights

ğŸ“ Goal: Learn the lifecycle of model serialization.
ğŸ”— Resources:

PyTorch state_dict tutorial: [https://pytorch.org/tutorials/beginner/saving_loading_models.html](https://pytorch.org/tutorials/beginner/saving_loading_models.html)

TensorFlow checkpoints (skim): [https://www.tensorflow.org/guide/checkpoint](https://www.tensorflow.org/guide/checkpoint)

### Day 9 â€” Burn: Loading and Using Model Weights

ğŸ“ Goal: Understand how Rust code loads parameters.
ğŸ”— Resource:

[Burn examples: https://github.com/tracel-ai/burn/tree/main/examples](Burn examples: https://github.com/tracel-ai/burn/tree/main/examples)

Look at how models load weights and run inference.

### Day 10 â€” Hands-On: Inspect a Modelâ€™s Weights

ğŸ“ Goal: Print shapes of real tensors to connect theory to practice.
ğŸ”— Resources:

Tutorial model (PyTorch): [https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)

(you donâ€™t need to train, just load)

Use Python:

import torch
sd = torch.hub.load_state_dict_from_url(...)
for k, v in sd.items():
    print(k, v.shape)

### Day 11 â€” safetensors Rust Code: Parser & Files

ğŸ“ Goal: Understand safetensors internals before contributing.
ğŸ”— Resource:

[https://github.com/huggingface/safetensors/tree/main/safetensors](https://github.com/huggingface/safetensors/tree/main/safetensors)

Inspect:

src/serde.rs

src/tensor.rs

src/error.rs

Focus on reading the header parsing logic.

### Day 12 â€” Read Burn or Candle Tensor Implementation

ğŸ“ Goal: Understand how tensors are stored & manipulated in Rust.

ğŸ”— Candle docs:

[https://github.com/huggingface/candle/tree/main/docs](https://github.com/huggingface/candle/tree/main/docs)

Look at:

tensors.md

devices.md

ğŸ”— Burn docs (alternative):

[https://burn.dev/book/guide/tensor.html](https://burn.dev/book/guide/tensor.html)

### Day 13 â€” Identify Fuzzing Targets / Contribution Areas

ğŸ“ Goal: Prepare your future PR.
Use your new ML understanding to list possible targets:

For safetensors, examples:

header parsing

data offsets

dtype mismatches

metadata validity checks

For Burn, examples:

tensor ops

model loaders

file format handlers

### Day 14 â€” Create Your Issue Draft / Contribution Plan

ğŸ“ Goal: Turn your learning into a concrete contribution.

Steps:

Pick safetensors or Burn

Write an issue titled:
â€œAdd fuzzing targets for X to improve safety and reliabilityâ€

Draft a PR with:

1 fuzz target

CI optional

clear test cases

This is your launchpad into the Rust ML ecosystem.

ğŸ‰ Done!

By the end of these 14 days, youâ€™ll be able to:

understand tensors and model weights

read ML model files

navigate safetensors or Burn internals

identify valid fuzzing or robustness contributions

open your first real PR
